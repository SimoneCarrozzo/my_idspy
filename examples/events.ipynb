{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24043496",
   "metadata": {},
   "source": [
    "# Event Examples\n",
    "\n",
    "This notebook demonstrates the event-driven system for pipeline monitoring, debugging, and observability through immutable events and centralized dispatch.\n",
    "\n",
    "## Features Demonstrated\n",
    "\n",
    "- **Event Class**: Immutable event objects with type, ID, constraints, and state\n",
    "- **Event Predicates**: Filtering functions for event matching and selection\n",
    "- **EventBus**: Centralized subscription and dispatching system with priority support\n",
    "- **BaseHandler**: Structured event handling with custom logic and filtering\n",
    "- **ObservablePipeline**: Pipeline integration with automatic event emission\n",
    "- **Error Handling**: Event-driven error tracking and pipeline diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1df2b274806a3f",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 30,
>>>>>>> upstream/main
   "id": "a8fcc8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project root to Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 31,
>>>>>>> upstream/main
   "id": "b91e35df280f80fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T18:24:07.476641Z",
     "start_time": "2025-09-03T18:24:07.472412Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.idspy.core.pipeline import PipelineEvent, ObservablePipeline   #pipeline che pubblica eventi su un EventBus\n",
    "from src.idspy.core.state import State\n",
    "from src.idspy.core.step import Step\n",
<<<<<<< HEAD
    "from src.idspy.events.bus import EventBus #sistema di messaggistica per la pubblicazione e sottoscrizione di eventi\n",
    "from src.idspy.events.events import Event, only_id #decoratore che filtra gli eventi per id"
=======
    "from src.idspy.events.bus import EventBus, BaseHandler\n",
    "from src.idspy.events.events import Event, only_id, id_startswith, has_payload_key, payload_equals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9446ea",
   "metadata": {},
   "source": [
    "## Event Class\n",
    "\n",
    "Immutable event objects with type, ID and payload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb848ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event as dict: {'type': 'pipeline_step', 'id': 'DataProcessor.Validation', 'payload': {'raw_data': {'rows': 10000, 'cols': 15}, 'memory_usage': '256MB', 'processing_time': 1.23}, 'timestamp': '2025-09-23T16:14:11.007506+00:00'}\n"
     ]
    }
   ],
   "source": [
    "# Event with complex nested data\n",
    "event = Event(\n",
    "    type=\"pipeline_step\",\n",
    "    id=\"DataProcessor.Validation\",\n",
    "    payload={\n",
    "        \"raw_data\": {\"rows\": 10000, \"cols\": 15},\n",
    "        \"memory_usage\": \"256MB\",\n",
    "        \"processing_time\": 1.23\n",
    "    }\n",
    ")\n",
    "\n",
    "# Events are immutable - this would raise an error:\n",
    "# event.type = \"different_type\"  # AttributeError!\n",
    "\n",
    "print(f\"Event as dict: {event.as_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc11838",
   "metadata": {},
   "source": [
    "### Event Predicates\n",
    "\n",
    "Filter functions for event matching: `only_id()`, `id_startswith()`, `has_constraint_key()`, `constraint_equals()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8200bca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event Predicate Examples:\n",
      "========================================\n",
      "Events with ID 'Pipeline.Load':\n",
      "  step_start :: Pipeline.Load\n",
      "  step_end :: Pipeline.Load\n",
      "\n",
      "Events with ID starting with 'Pipeline.':\n",
      "  step_start :: Pipeline.Load\n",
      "  step_start :: Pipeline.Transform\n",
      "  step_end :: Pipeline.Load\n",
      "\n",
      "Events with 'duration' payload:\n",
      "  step_end :: Pipeline.Load (duration: 1.5)\n",
      "\n",
      "Events with type='input':\n",
      "  step_start :: Pipeline.Load\n"
     ]
    }
   ],
   "source": [
    "# Create some test events\n",
    "events = [\n",
    "    Event(\"step_start\", \"Pipeline.Load\", payload={\"index\": 0, \"type\": \"input\"}),\n",
    "    Event(\"step_start\", \"Pipeline.Transform\", payload={\"index\": 1, \"type\": \"processing\"}),\n",
    "    Event(\"step_end\", \"Pipeline.Load\", payload={\"index\": 0, \"duration\": 1.5}),\n",
    "    Event(\"error\", \"OtherPipeline.Validate\", payload={\"error_code\": 404}),\n",
    "]\n",
    "\n",
    "print(\"Event Predicate Examples:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Test only_id predicate\n",
    "load_predicate = only_id(\"Pipeline.Load\")\n",
    "print(\"Events with ID 'Pipeline.Load':\")\n",
    "for event in filter(load_predicate, events):\n",
    "    print(f\"  {event.type} :: {event.id}\")\n",
    "\n",
    "# Test id_startswith predicate\n",
    "pipeline_predicate = id_startswith(\"Pipeline.\")\n",
    "print(\"\\nEvents with ID starting with 'Pipeline.':\")\n",
    "for event in filter(pipeline_predicate, events):\n",
    "    print(f\"  {event.type} :: {event.id}\")\n",
    "\n",
    "# Test has_payload_key predicate\n",
    "has_duration = has_payload_key(\"duration\")\n",
    "print(\"\\nEvents with 'duration' payload:\")\n",
    "for event in filter(has_duration, events):\n",
    "    print(f\"  {event.type} :: {event.id} (duration: {event.payload['duration']})\")\n",
    "\n",
    "# Test payload_equals predicate\n",
    "input_type = payload_equals(\"type\", \"input\")\n",
    "print(\"\\nEvents with type='input':\")\n",
    "for event in filter(input_type, events):\n",
    "    print(f\"  {event.type} :: {event.id}\")"
>>>>>>> upstream/main
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ec82350ec72c07",
   "metadata": {},
   "source": [
    "## EventBus\n",
    "\n",
    "Centralized event dispatching with subscription patterns and priority control."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "b1dc274996e73bca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T18:24:07.494347Z",
     "start_time": "2025-09-03T18:24:07.489350Z"
=======
   "execution_count": 34,
   "id": "a1d98600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing EventBus Subscriptions:\n",
      "========================================\n",
      "\n",
      "Publishing: user_action :: login\n",
      "[USER] Action: authenticate\n",
      "[GLOBAL] user_action from login\n",
      "\n",
      "Publishing: system_event :: maintenance\n",
      "[GLOBAL] system_event from maintenance\n",
      "\n",
      "Publishing: pipeline_step :: Pipeline.Process\n",
      "[MANUAL] pipeline_step\n",
      "[GLOBAL] pipeline_step from Pipeline.Process\n",
      "\n",
      "Publishing: other_event :: misc\n",
      "[GLOBAL] other_event from misc\n",
      "\n",
      "Unsubscribing token 5: True\n",
      "After unsubscription:\n",
      "[GLOBAL] pipeline_step from Pipeline.Another\n"
     ]
>>>>>>> upstream/main
    }
   ],
   "source": [
<<<<<<< HEAD
    "bus = EventBus()\n",
    "#spiegando i seguenti metodi: \n",
    "# log_all: si iscrive a tutti gli eventi e stampa una riga di log con il tipo e l'id dell'evento.\n",
    "# on_before: si iscrive all'evento BEFORE_STEP e stampa l'indice dello step, i requisiti e cosa fornisce.\n",
    "# on_before_sum: si iscrive all'evento BEFORE_STEP ma solo per lo step con id \"Demo.Sum\" e stampa un messaggio specifico.\n",
    "# on_after: si iscrive all'evento AFTER_STEP e stampa l'indice dello step.\n",
    "# on_err: si iscrive all'evento ON_ERROR e stampa un messaggio di errore con l'id dello step e il messaggio di errore.\n",
=======
    "# Demonstrate EventBus subscription patterns\n",
    "demo_bus = EventBus()\n",
    "\n",
    "# Pattern 1: Function-based handlers with decorators\n",
    "@demo_bus.on()  # Subscribe to ALL events\n",
    "def global_logger(event: Event) -> None:\n",
    "    print(f\"[GLOBAL] {event.type} from {event.id}\")\n",
>>>>>>> upstream/main
    "\n",
    "@demo_bus.on(\"user_action\")  # Subscribe to specific event type\n",
    "def user_action_handler(event: Event) -> None:\n",
    "    print(f\"[USER] Action: {event.payload.get('action', 'unknown')}\")\n",
    "\n",
    "@demo_bus.on(\"system_event\", predicate=has_payload_key(\"user\"), priority=0)  # With predicate and priority (default 1)\n",
    "def priority_system_handler(event: Event) -> None:\n",
    "    user = event.payload.get(\"user\")\n",
    "    print(f\"[USER] priority 0 System event for user: {user}\")\n",
    "\n",
    "@demo_bus.on(\"system_event\", predicate=has_payload_key(\"user\"), priority=2)\n",
    "def priority_system_handler(event: Event) -> None:\n",
    "    user = event.payload.get(\"user\")\n",
    "    print(f\"[USER] priority 2 System event for user: {user}\")\n",
    "\n",
    "# Pattern 2: Manual subscription with tokens\n",
    "token1 = demo_bus.subscribe(\n",
    "    lambda e: print(f\"[MANUAL] {e.type}\"),\n",
    "    event_type=\"pipeline_step\"\n",
    ")\n",
    "\n",
    "# Test the subscriptions\n",
    "print(\"Testing EventBus Subscriptions:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "test_events = [\n",
    "    Event(\"user_action\", \"login\", payload={\"action\": \"authenticate\", \"user\": \"alice\"}),\n",
    "    Event(\"system_event\", \"maintenance\", payload={\"priority\": \"high\", \"duration\": 30}),\n",
    "    Event(\"pipeline_step\", \"Pipeline.Process\", payload={\"index\": 1}),\n",
    "    Event(\"other_event\", \"misc\", payload={\"data\": \"test\"}),\n",
    "]\n",
    "\n",
<<<<<<< HEAD
    "#AGGIUNTO\n",
    "@bus.on(PipelineEvent.AFTER_STEP.value, only_id(\"Demo.Multiply\"))\n",
    "def on_after_mul(ev: Event) -> None:\n",
    "        idx = ev.payload.get(\"index\")\n",
    "        print(f\"[AFTER] multipling idx={idx} step={ev.id}\")\n",
    "\n",
    "\n",
    "@bus.on(PipelineEvent.AFTER_STEP.value)\n",
    "def on_after(ev: Event) -> None:\n",
    "    idx = ev.payload.get(\"index\")\n",
    "    print(f\"[AFTER]  idx={idx} step={ev.id}\")\n",
=======
    "for event in test_events:\n",
    "    print(f\"\\nPublishing: {event.type} :: {event.id}\")\n",
    "    demo_bus.publish(event)\n",
>>>>>>> upstream/main
    "\n",
    "# Demonstrate unsubscription\n",
    "print(f\"\\nUnsubscribing token {token1}: {demo_bus.unsubscribe(token1)}\")\n",
    "print(\"After unsubscription:\")\n",
    "demo_bus.publish(Event(\"pipeline_step\", \"Pipeline.Another\", payload={\"index\": 2}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e085a79",
   "metadata": {},
   "source": [
    "## BaseHandler\n",
    "\n",
    "Structured event handling with custom logic and filtering capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78c29a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing BaseHandler Implementations:\n",
      "==================================================\n",
      "\n",
      "Publishing: before_step :: TestPipeline.Load\n",
      "[MONITOR] TestPipeline starting step 1: TestPipeline.Load\n",
      "\n",
      "Publishing: after_step :: TestPipeline.Load\n",
      "[MONITOR] TestPipeline completed step: TestPipeline.Load\n",
      "\n",
      "Publishing: before_step :: TestPipeline.Process\n",
      "[MONITOR] TestPipeline starting step 2: TestPipeline.Process\n",
      "\n",
      "Publishing: error :: TestPipeline.Process\n",
      "\n",
      "Publishing: after_step :: OtherPipeline.Export\n"
     ]
    }
   ],
   "source": [
    "# Example: Conditional pipeline monitor\n",
    "class PipelineMonitor(BaseHandler):\n",
    "    def __init__(self, pipeline_name: str):\n",
    "        super().__init__()\n",
    "        self.pipeline_name = pipeline_name\n",
    "        self.current_step = None\n",
    "        self.step_count = 0\n",
    "\n",
    "    def can_handle(self, event: Event) -> bool:\n",
    "        # Only handle events from our specific pipeline\n",
    "        return event.id.startswith(f\"{self.pipeline_name}.\")\n",
    "\n",
    "    def handle(self, event: Event) -> None:\n",
    "        if event.type == \"before_step\":\n",
    "            self.current_step = event.id\n",
    "            self.step_count += 1\n",
    "            print(f\"[MONITOR] {self.pipeline_name} starting step {self.step_count}: {event.id}\")\n",
    "        elif event.type == \"after_step\":\n",
    "            print(f\"[MONITOR] {self.pipeline_name} completed step: {event.id}\")\n",
    "            self.current_step = None\n",
    "\n",
    "handler_bus = EventBus()\n",
    "pipeline_monitor = PipelineMonitor(\"TestPipeline\")\n",
    "handler_bus.subscribe(pipeline_monitor)\n",
    "\n",
    "# Test with various events\n",
    "test_events = [\n",
    "    Event(\"before_step\", \"TestPipeline.Load\", payload={\"index\": 0}),\n",
    "    Event(\"after_step\", \"TestPipeline.Load\", payload={\"index\": 0, \"duration\": 1.2}),\n",
    "    Event(\"before_step\", \"TestPipeline.Process\", payload={\"index\": 1}),\n",
    "    Event(\"error\", \"TestPipeline.Process\", payload={\"error\": \"Invalid data format\"}),\n",
    "    Event(\"after_step\", \"OtherPipeline.Export\", payload={\"index\": 2, \"duration\": 0.8}),\n",
    "]\n",
    "\n",
    "print(\"Testing BaseHandler Implementations:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for event in test_events:\n",
    "    print(f\"\\nPublishing: {event.type} :: {event.id}\")\n",
    "    handler_bus.publish(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d57951",
   "metadata": {},
   "source": [
    "## ObservablePipeline\n",
    "\n",
    "Pipeline integration with automatic event emission for monitoring and debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6c2df733328d40",
   "metadata": {},
   "source": [
    "### Example Steps"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 36,
>>>>>>> upstream/main
   "id": "bed906bcd8ad3a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T18:24:07.504436Z",
     "start_time": "2025-09-03T18:24:07.500944Z"
    }
   },
   "outputs": [],
   "source": [
    "class Load(Step):\n",
    "    @Step.provides(data=list)\n",
    "    def run(self, state: State, **inputs) -> dict:\n",
    "        return {\"data\": [1, 2, 3]}\n",
    "\n",
    "class Sum(Step):\n",
    "    @Step.requires(data=list)\n",
    "    @Step.provides(sum=int)\n",
    "    def run(self, state: State, data, **inputs) -> dict:\n",
    "        return {\"sum\": sum(data)}\n",
    "\n",
    "class Boom(Step):\n",
    "    @Step.requires(missing=object)\n",
    "    def run(self, state: State, **inputs) -> dict:\n",
    "        # never reached because requires isn't satisfied\n",
<<<<<<< HEAD
    "        pass\n",
    "\n",
    "#NUOVE AGGIUNTE\n",
    "class Multiply(Step):\n",
    "    def __init__(self, factor: int):\n",
    "        super().__init__(requires=[\"data\"], provides=[\"mul\"])\n",
    "        self.factor = factor\n",
    "\n",
    "    def run(self, state: State) -> None:\n",
    "        state[\"mul\"] = [x * self.factor for x in state[\"data\"]]\n",
    "\n",
    "class Pitagora(Step):\n",
    "    def __init__(self):\n",
    "        super().__init__(requires=[\"data\"], provides=[\"pitagora\"])\n",
    "\n",
    "    def run(self, state: State):\n",
    "        \n",
    "        if len(state[\"data\"]) < 2:\n",
    "            state[\"pitagora\"] = None\n",
    "        else:\n",
    "            list_pitagora = []\n",
    "            for i in range(len(state[\"data\"]) - 1):\n",
    "                a = state[\"data\"][i]\n",
    "                b = state[\"data\"][i + 1]\n",
    "                list_pitagora.append(int((a**2 + b**2) ** 0.5))\n",
    "            state[\"pitagora\"] = list_pitagora     \n",
    "#FINE NUOVE AGGIUNTE\n"
=======
    "        return {}"
>>>>>>> upstream/main
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aff07650a76952",
   "metadata": {},
   "source": [
    "### Observable Pipeline Execution"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 37,
>>>>>>> upstream/main
   "id": "9b15820328ca9184",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T18:24:07.513086Z",
     "start_time": "2025-09-03T18:24:07.510094Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[ALL] PipelineEvent.PIPELINE_START :: Demo\n",
      "[BEFORE] idx=0 step=Demo.Load requires=[] provides=['data']\n",
      "[ALL] PipelineEvent.BEFORE_STEP :: Demo.Load\n",
      "[AFTER]  idx=0 step=Demo.Load\n",
      "[ALL] PipelineEvent.AFTER_STEP :: Demo.Load\n",
      "[BEFORE] idx=1 step=Demo.Sum requires=['data'] provides=['sum']\n",
      "[BEFORE] summing step=Demo.Sum\n",
      "[ALL] PipelineEvent.BEFORE_STEP :: Demo.Sum\n",
      "[AFTER]  idx=1 step=Demo.Sum\n",
      "[ALL] PipelineEvent.AFTER_STEP :: Demo.Sum\n",
      "[BEFORE] idx=2 step=Demo.Multiply requires=['data'] provides=['mul']\n",
      "[ALL] PipelineEvent.BEFORE_STEP :: Demo.Multiply\n",
      "[AFTER]  idx=2 step=Demo.Multiply\n",
      "[ALL] PipelineEvent.AFTER_STEP :: Demo.Multiply\n",
      "[BEFORE] idx=3 step=Demo.Pitagora requires=['data'] provides=['pitagora']\n",
      "[ALL] PipelineEvent.BEFORE_STEP :: Demo.Pitagora\n",
      "[AFTER]  idx=3 step=Demo.Pitagora\n",
      "[ALL] PipelineEvent.AFTER_STEP :: Demo.Pitagora\n",
      "[ALL] PipelineEvent.PIPELINE_END :: Demo\n",
      "STATE: {'data': [1, 2, 3], 'sum': 6, 'mul': [2, 4, 6], 'pitagora': [2, 3]}\n"
=======
      "=== ObservablePipeline Demo ===\n",
      "[GLOBAL] PipelineEvent.PIPELINE_START from Demo\n",
      "[PipelineEvent.PIPELINE_START] Demo\n",
      "[GLOBAL] PipelineEvent.BEFORE_STEP from Demo.Load\n",
      "[PipelineEvent.BEFORE_STEP] Demo.Load\n",
      "[GLOBAL] PipelineEvent.AFTER_STEP from Demo.Load\n",
      "[PipelineEvent.AFTER_STEP] Demo.Load\n",
      "[GLOBAL] PipelineEvent.BEFORE_STEP from Demo.Sum\n",
      "[PipelineEvent.BEFORE_STEP] Demo.Sum\n",
      "[GLOBAL] PipelineEvent.AFTER_STEP from Demo.Sum\n",
      "[PipelineEvent.AFTER_STEP] Demo.Sum\n",
      "[GLOBAL] PipelineEvent.PIPELINE_END from Demo\n",
      "[PipelineEvent.PIPELINE_END] Demo\n",
      "\n",
      "Final STATE: {'data': [1, 2, 3], 'sum': 6}\n"
>>>>>>> upstream/main
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "\"\"\" p = ObservablePipeline([Load(), Sum()], name=\"Demo\", bus=bus)\n",
    "\n",
    "s = State()\n",
    "p(s)\n",
    "print(\"STATE:\", s.to_dict()) \"\"\"\n",
    "# Expected:\n",
    "# [ALL] PipelineEvent.PIPELINE_START :: Demo\n",
    "# [BEFORE] idx=0 step=Demo.Load requires=[] provides=['data']\n",
    "# [ALL] PipelineEvent.BEFORE_STEP :: Demo.Load\n",
    "# [AFTER]  idx=0 step=Demo.Load\n",
    "# [ALL] PipelineEvent.AFTER_STEP :: Demo.Load\n",
    "# [BEFORE] idx=1 step=Demo.Sum requires=['data'] provides=['sum']\n",
    "# [BEFORE] summing step=Demo.Sum\n",
    "# [ALL] PipelineEvent.BEFORE_STEP :: Demo.Sum\n",
    "# [AFTER]  idx=1 step=Demo.Sum\n",
    "# [ALL] PipelineEvent.AFTER_STEP :: Demo.Sum\n",
    "# [ALL] PipelineEvent.PIPELINE_END :: Demo\n",
    "# STATE: {'data': [1, 2, 3], 'sum': 6}\n",
    "\n",
    "#NUOVE AGGIUNTE\n",
    "p1 = ObservablePipeline([Load(), Sum(), Multiply(factor=2), Pitagora()], name=\"Demo\", bus=bus)\n",
    "\n",
    "s1 = State()\n",
    "p1(s1)\n",
    "print(\"STATE:\", s1.to_dict())\n",
    "#fine nuove aggiunte"
=======
    "# Create and run an ObservablePipeline\n",
    "bus = EventBus()\n",
    "@bus.on(priority=0)\n",
    "def global_logger(event: Event) -> None:\n",
    "    print(f\"[GLOBAL] {event.type} from {event.id}\")\n",
    "\n",
    "@bus.on(PipelineEvent.PIPELINE_START)\n",
    "def global_logger(event: Event) -> None:\n",
    "    print(f\"[{event.type}] {event.id}\")\n",
    "\n",
    "@bus.on(PipelineEvent.PIPELINE_END)\n",
    "def global_logger(event: Event) -> None:\n",
    "    print(f\"[{event.type}] {event.id}\")\n",
    "\n",
    "@bus.on(PipelineEvent.BEFORE_STEP)\n",
    "def global_logger(event: Event) -> None:\n",
    "    print(f\"[{event.type}] {event.id}\")\n",
    "\n",
    "@bus.on(PipelineEvent.AFTER_STEP)\n",
    "def global_logger(event: Event) -> None:\n",
    "    print(f\"[{event.type}] {event.id}\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"=== ObservablePipeline Demo ===\")\n",
    "p = ObservablePipeline(steps=[Load(), Sum()], bus=bus, name=\"Demo\")\n",
    "\n",
    "s = State()\n",
    "p(s)\n",
    "print(f\"\\nFinal STATE: {s.as_dict()}\")"
>>>>>>> upstream/main
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2e250c69aa80ea",
   "metadata": {},
   "source": [
    "### Error Handling"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 38,
>>>>>>> upstream/main
   "id": "6d041f17ee1430d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T18:24:07.527943Z",
     "start_time": "2025-09-03T18:24:07.525462Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GLOBAL] PipelineEvent.PIPELINE_START from ErrDemo\n",
      "[PipelineEvent.PIPELINE_START] ErrDemo\n",
      "[GLOBAL] PipelineEvent.BEFORE_STEP from ErrDemo.Boom\n",
      "[PipelineEvent.BEFORE_STEP] ErrDemo.Boom\n",
      "[GLOBAL] PipelineEvent.ON_ERROR from ErrDemo.Boom\n",
      "[ERROR] ErrDemo.Boom\n",
      "[GLOBAL] PipelineEvent.PIPELINE_END from ErrDemo\n",
      "[PipelineEvent.PIPELINE_END] ErrDemo\n"
     ]
    }
   ],
   "source": [
    "@bus.on(PipelineEvent.ON_ERROR)\n",
    "def global_logger(event: Event) -> None:\n",
    "    print(f\"[ERROR] {event.id}\")\n",
    "\n",
    "p_err = ObservablePipeline([Boom()], name=\"ErrDemo\", bus=bus)\n",
    "\n",
    "try:\n",
    "    p_err(State())\n",
    "except KeyError:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
